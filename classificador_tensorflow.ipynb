{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exemplo Classificador de Flores - TensorFlow\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iris.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandromoreira/anaconda/envs/deeplearning/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "COLUMN_NAMES = [\n",
    "        'SepalLength', \n",
    "        'SepalWidth',\n",
    "        'PetalLength', \n",
    "        'PetalWidth', \n",
    "        'Species'\n",
    "        ]\n",
    "\n",
    "# Importando dataset de treinamento\n",
    "training_dataset = pd.read_csv('iris_training.csv', names=COLUMN_NAMES, header=0)\n",
    "train_x = training_dataset.iloc[:, 0:4]\n",
    "train_y = training_dataset.iloc[:, 4]\n",
    "\n",
    "# Importando dataset de teste\n",
    "test_dataset = pd.read_csv('iris_test.csv', names=COLUMN_NAMES, header=0)\n",
    "test_x = test_dataset.iloc[:, 0:4]\n",
    "test_y = test_dataset.iloc[:, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iris_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, precisamos definir colunas de recursos, que irão ajudar a nossa Rede Neural.\n",
    "\n",
    "columns_feat = [\n",
    "\n",
    "    tf.feature_column.numeric_column(key='SepalLength'),\n",
    "    tf.feature_column.numeric_column(key='SepalWidth'),\n",
    "    tf.feature_column.numeric_column(key='PetalLength'),\n",
    "    tf.feature_column.numeric_column(key='PetalWidth')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iris_modelo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j4/f5p_3xrn2n12xxlnz1t9p2q40000gn/T/tmp5zz4lm6u\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_num_ps_replicas': 0, '_service': None, '_is_chief': True, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12711c208>, '_log_step_count_steps': 100, '_tf_random_seed': None, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_model_dir': '/var/folders/j4/f5p_3xrn2n12xxlnz1t9p2q40000gn/T/tmp5zz4lm6u', '_master': '', '_task_type': 'worker'}\n"
     ]
    }
   ],
   "source": [
    "#Construindo a Rede Neural - DNNClassifier\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "\n",
    "    feature_columns=columns_feat,\n",
    "\n",
    "    # 2 camadas ocultas com 10 nós cada\n",
    "    hidden_units=[10, 10],\n",
    "\n",
    "    # O modelo está classificando 3 classes\n",
    "    n_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/j4/f5p_3xrn2n12xxlnz1t9p2q40000gn/T/tmp5zz4lm6u/model.ckpt.\n",
      "INFO:tensorflow:loss = 279.108, step = 1\n",
      "INFO:tensorflow:global_step/sec: 416.244\n",
      "INFO:tensorflow:loss = 11.7686, step = 101 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.225\n",
      "INFO:tensorflow:loss = 8.41222, step = 201 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.993\n",
      "INFO:tensorflow:loss = 7.14272, step = 301 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.656\n",
      "INFO:tensorflow:loss = 6.50101, step = 401 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.384\n",
      "INFO:tensorflow:loss = 6.3734, step = 501 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.229\n",
      "INFO:tensorflow:loss = 6.39307, step = 601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.23\n",
      "INFO:tensorflow:loss = 3.95554, step = 701 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.867\n",
      "INFO:tensorflow:loss = 3.35254, step = 801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.226\n",
      "INFO:tensorflow:loss = 6.19452, step = 901 (0.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/j4/f5p_3xrn2n12xxlnz1t9p2q40000gn/T/tmp5zz4lm6u/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.23017.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x126861710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo função de treinamento\n",
    "\n",
    "def train_function(inputs, outputs, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(inputs), outputs))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "#Treinar o Modelo\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_function(train_x, train_y, 100),\n",
    "    steps=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-14-11:49:15\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/j4/f5p_3xrn2n12xxlnz1t9p2q40000gn/T/tmp5zz4lm6u/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-14-11:49:16\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.966667, average_loss = 0.0483003, global_step = 1000, loss = 1.44901\n"
     ]
    }
   ],
   "source": [
    "#Definindo função de avaliação\n",
    "def evaluation_function(attributes, classes, batch_size):\n",
    "    attributes=dict(attributes)\n",
    "    if classes is None:\n",
    "        inputs = attributes\n",
    "    else:\n",
    "        inputs = (attributes, classes)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Avaliando o classificador\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:evaluation_function(test_x, test_y, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1],\n",
    "    'SepalWidth': [3.3],\n",
    "    'PetalLength': [1.7],\n",
    "    'PetalWidth': [0.5],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                            batch_size=args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-58f756dcf900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[1;32m    419\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       features, input_hooks = self._get_features_from_input_fn(\n\u001b[0;32m--> 421\u001b[0;31m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[1;32m    422\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m    423\u001b[0m           features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_features_from_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0minput_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-64f72e3935b1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions = classifier.predict(\n\u001b[0;32m----> 2\u001b[0;31m     input_fn=lambda:iris_data.eval_input_fn(predict_x,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                             batch_size=args.batch_size))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iris_data' is not defined"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
